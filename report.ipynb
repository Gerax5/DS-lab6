{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80499247",
   "metadata": {},
   "source": [
    "# Lab 6\n",
    "\n",
    "Daniel Alfredo Rayo Roldan\n",
    "\n",
    "Gerardo Gabriel Pineda Riveiro\n",
    "\n",
    "https://github.com/Gerax5/DS-lab6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426d0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stop\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "from textblob import TextBlob\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                           accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, roc_auc_score, roc_curve)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import requests\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc8fcf2",
   "metadata": {},
   "source": [
    "## Cargado de Datos\n",
    "\n",
    "Para este reporte se trabajó con un junton de datos igual a , que consistian 7613 en mensajes que tenian representaban mensajes positivos o negativos, las frases estaban escritas de un modo que solo usando el contexto y con conocimiento de la semantíca se podía entender si una frase representaba una catastrofe real o solamente figurada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69193eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Error parseando línea: Expecting ',' delimiter: line 1 column 4314 (char 4313)\n",
      "Línea problemática: {\"id\": 1711127305131631071, \"id_str\": \"1711127305131631071\", \"url\": \"https://x.com/nquevedoa/status/1711127305131631071\", \"date\": \"2023-10-08 21:11:55+00:00\", \"user\": {\"id\": 204996481, \"id_str\": \"2049 ...\n",
      "Se cargaron 5604 tweets\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "\n",
    "with open(\"data/traficogt.txt\", \"r\", encoding=\"utf-16\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            tweets.append(tweet)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"⚠️ Error parseando línea:\", e)\n",
    "            print(\"Línea problemática:\", line[:200], \"...\")\n",
    "            continue\n",
    "\n",
    "print(f\"Se cargaron {len(tweets)} tweets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9940e990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No se encontró ningún retweet\n"
     ]
    }
   ],
   "source": [
    "first_rt = None\n",
    "for i, tweet in enumerate(tweets):\n",
    "    if tweet.get(\"retweetedTweet\") is not None:\n",
    "        first_rt = (i, tweet)\n",
    "        break\n",
    "\n",
    "if first_rt:\n",
    "    idx, tw = first_rt\n",
    "    print(f\"El primer retweet está en tweets[{idx}]\")\n",
    "    print(\"ID:\", tw[\"id\"])\n",
    "    print(\"Usuario:\", tw[\"user\"][\"username\"])\n",
    "    print(\"Texto:\", tw[\"rawContent\"])\n",
    "else:\n",
    "    print(\"No se encontró ningún retweet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197de489",
   "metadata": {},
   "source": [
    "### Para llevarnos\n",
    "\n",
    "# user\n",
    "* Username\n",
    "* id_str\n",
    "* followersCount\n",
    "* friendsCount\n",
    "* mediaCount\n",
    "* verified\n",
    "# rawContent\n",
    "# likeCount\n",
    "# quoteCount\n",
    "# hashtags\n",
    "# cashtags\n",
    "# mentionedUsers\n",
    "# viewCount\n",
    "# retweetedTweet\n",
    "# quotedTweet -> id\n",
    "\n",
    "\n",
    "---\n",
    "# quotedTweet\n",
    "# user\n",
    "* Username\n",
    "* id_str\n",
    "* followersCount\n",
    "* friendsCount\n",
    "* mediaCount\n",
    "* verified\n",
    "# rawContent\n",
    "# likeCount\n",
    "# quoteCount\n",
    "# hashtags\n",
    "# cashtags\n",
    "# mentionedUsers\n",
    "# viewCount\n",
    "# retweetedTweet\n",
    "# quotedTweet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
